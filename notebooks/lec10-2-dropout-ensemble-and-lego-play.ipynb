{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 10-2. Dropout & Model Ensemble\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting 체크방법\n",
    "- 학습데이터는 good ! ( blue )\n",
    "- Testset으로는 점수가 낮음 ( red )\n",
    " - X 축 : layers 수 ( 특정 시점을 지난 순간 overfiiting 발생: error 증가 )\n",
    "<img src=\"./img/10-dropout-01.png\", width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions for overfitting\n",
    "- More training data !\n",
    "- Reduce the number of features\n",
    "- **Regularization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "- Let's not have too big numbers in the weight\n",
    "\n",
    "- L2_reg : $cost + \\lambda \\sum W^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "- Regularization\n",
    "- randomly set some neurons to zero in the forward pass\n",
    "\n",
    "<img src=\"./img/10-dropout-02.png\", width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How could this possibly be a good idea ?\n",
    "- 각 뉴런들을 랜덤하게 쉬게 하고 나머지 뉴런들을 갖고 맞추도록 훈련시킴 ( 더 빡세게 훈련 ? )\n",
    "- 마지막 Test 에서는 모든 뉴런을 총 동원하여 예측을 함 !\n",
    "\n",
    "<img src=\"./img/10-dropout-03.png\", width=400>\n",
    "\n",
    "```\n",
    "dropout_rate = tf.placeholder(\"float\")\n",
    "_L1 = tf.nn.relu(tf.add(tf.matmul(X, W1), B1))\n",
    "L1 = tf.nn.dropout(_L1, dropout_rate)\n",
    "\n",
    "# Train:\n",
    "sess.run(optimizer, feed_dict={X: batch_xs, Y: batch_ys, dropout_rate: 0.7})\n",
    "\n",
    "# Test(Evaluation):\n",
    "print(\"Accuracy:\", accuracy.eval({X: mnist.test.imgaes, Y: mnist.test.labels, dropout_rate: 1}))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble\n",
    "- 독립적으로 뉴럴넷을 여러개 만듦 ( $n$ 개 )\n",
    "- 트레이닝셋도 각각 배정 ( 모두 같게 하여도 됨 )\n",
    "- 각각 결과를 종합 ( 전문가 $n$ 명에게 물어봐서 결론 도출 )\n",
    "- 실제 2% 에서 최대 4-5% 까지 성능이 올라감\n",
    "\n",
    "<img src=\"./img/10-ensemble-01.png\", width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## NN Lego Play !\n",
    "- Neural Nets 을 조립하는게 레고와 같음\n",
    "- 쪼개고, 합하고, 건너뛰고, 반복하고(재귀) 자유롭게 만들 수 있음\n",
    "- The only limit is your imagination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### He's LessNet 구조\n",
    "<img src=\"./img/10-lego-01.png\", width=400>\n",
    "\n",
    "### Split & merge\n",
    "<img src=\"./img/10-lego-02.png\", width=350>\n",
    "\n",
    "### Recurrent network ( RNN )\n",
    "<img src=\"./img/10-lego-03.png\", width=350>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

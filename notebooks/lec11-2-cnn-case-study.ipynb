{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Lecture 11-2. ConvNet 의 활용예\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Case Study: LeNet-5\n",
    "- 가장 처음 ConvNet 을 구상\n",
    "- 32x32 input 이 주어짐\n",
    "- 6개의 5x5 filter, stride 1 로 conv -> 6@28x28\n",
    "- 2x2, strid 2 로 pooling ( subsampling ) -> 6@14x14\n",
    "\n",
    "\n",
    "![](./img/11-case-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Case Study: AlexNet\n",
    "- 227x227x3 input ( colored )\n",
    "- 96개의 11x11x3 filter, stride 4 로 conv -> 55x55x96\n",
    "- Parameters: (11\\*11\\*3)\\*96 = 35K\n",
    "- **Second layer** (POOL1): 3x3 filter, stride 2 -> 27x27x96\n",
    "- Paramters: 0!\n",
    "- ... 반복\n",
    "- Normalization layer 도 있으나 최근들어서는 많이 사용 안함\n",
    "- 마지막에 나온 6x6x256 output 을 FC layer 에 넣음\n",
    "- 최종적으로 1000 neurons 로 출력 ( = labels )\n",
    "- 그리고 이같은 CNN 을 7개 사용하여 ensemble 하였더니 성능이 더 개선\n",
    "\n",
    "\n",
    "![](./img/11-case-02.png)\n",
    "![](./img/11-case-03.png)\n",
    "![](./img/11-case-04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Case Study: GoogLeNet\n",
    "- Inception module ( 창의적으로 )\n",
    " - 1x1(conv), 1x1(conv), 3x3(pooling) \n",
    " - 3x3(conv), 5x5(conv), 1x1(conv)\n",
    " - 다양한 형태로 conv 와 pooling 을 구성\n",
    "\n",
    "![](./img/11-case-05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Case Study: ResNet\n",
    "- 2015년 최고의 발전, 인간보다 더 잘 분류하는 3.6% 에러 성능\n",
    "- AlexNet 은 8개 layers\n",
    "- VGG 는 19 layers\n",
    "- 그러나 **ResNet** 은 **152 개 layers**\n",
    " - 엄청나게 layer 숫자가 많음\n",
    " - layer 가 깊으면 학습하기 어려움\n",
    "- 이를 극복하기 위해 **Fastforawrd** 사용\n",
    "\n",
    "![](./img/11-case-06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fast-forward\n",
    "- layer 를 순차적으로 지나가는 것이 아니라, 점프해서 지나감\n",
    "- layer 의 갯수는 많지만, 실제로 학습하는 입장에서는 별로 layer 가 깊지 않다!\n",
    "- 그러나 왜 이것이 잘되는지는 아직 모름\n",
    "\n",
    "![](./img/11-case-07.png)\n",
    "![](./img/11-case-08.png)\n",
    "\n",
    "### Inception module 과 비슷한 원리라 볼 수 있음\n",
    "![](./img/11-case-09.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN for Sentence classification\n",
    "- 이미지가 아닌 텍스트를 CNN 으로 분류\n",
    "\n",
    "![](./img/11-case-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## AlphaGo Paper\n",
    "- 19x19x48 이미지를 input 으로 사용\n",
    "- 처음 5개의 hidden layer 는 zero padding -> 23x23\n",
    "- k 개의 5x5 filters 를 사용.\n",
    "- ...\n",
    "\n",
    "![](./img/11-case-11.png)\n",
    "![](./img/11-case-12.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
